{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q google-adk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:00:05.563755Z","iopub.execute_input":"2025-11-29T21:00:05.564088Z","iopub.status.idle":"2025-11-29T21:00:10.570955Z","shell.execute_reply.started":"2025-11-29T21:00:05.564059Z","shell.execute_reply":"2025-11-29T21:00:10.569684Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Use your GOOGLE_API_KEY and SERPAPI_API_KEY as plain text in this block\n\nimport os\n\nPLAIN_GOOGLE_API_KEY = \"user_google_api_key\"\nPLAIN_SERPAPI_API_KEY = \"user_serp_api_key\"\n\ndef resolve_api_key(env_name: str, plain_value: str = \"\"):\n    if plain_value:\n        key = plain_value.strip()\n        os.environ[env_name] = key\n        return key\n\n    # No key found\n    raise RuntimeError(\n        f\"âŒ No value found for {env_name}.\\n\"\n        f\"Please either:\\n\"\n        f\"  â€¢ Set {env_name} as an environment variable, OR\\n\"\n        f\"  â€¢ Put your key in PLAIN_{env_name} inside the script.\"\n    )\n\n\nGOOGLE_API_KEY = resolve_api_key(\"GOOGLE_API_KEY\", PLAIN_GOOGLE_API_KEY)\nSERPAPI_API_KEY = resolve_api_key(\"SERPAPI_API_KEY\", PLAIN_SERPAPI_API_KEY)\n\nprint(\"\\n API key setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:00:21.513265Z","iopub.execute_input":"2025-11-29T21:00:21.513720Z","iopub.status.idle":"2025-11-29T21:00:21.521200Z","shell.execute_reply.started":"2025-11-29T21:00:21.513686Z","shell.execute_reply":"2025-11-29T21:00:21.520072Z"}},"outputs":[{"name":"stdout","text":"\n API key setup complete!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\nimport requests\nfrom typing import List, Dict, Optional\nimport asyncio\nimport json\nimport re\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:00:31.815767Z","iopub.execute_input":"2025-11-29T21:00:31.816085Z","iopub.status.idle":"2025-11-29T21:01:01.312729Z","shell.execute_reply.started":"2025-11-29T21:00:31.816061Z","shell.execute_reply":"2025-11-29T21:01:01.311755Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1, # Initial delay before first retry (in seconds)\n    http_status_codes=[429, 500, 503, 504] # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:04.904140Z","iopub.execute_input":"2025-11-29T21:01:04.904760Z","iopub.status.idle":"2025-11-29T21:01:04.909926Z","shell.execute_reply.started":"2025-11-29T21:01:04.904729Z","shell.execute_reply":"2025-11-29T21:01:04.909061Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Custom tool for SearchAgent\n\ndef google_scholar_search(\n    query: str,\n    max_results: int = 20\n) -> Dict:\n    \"\"\"\n    Search academic literature using the SerpAPI Google Scholar API.\n\n    Args:\n        query (str): Keywords or query string describing the research topic.\n        max_results (int, optional): Maximum number of papers to return (default: 20).\n\n    Returns:\n        dict: A dictionary with:\n            - status (str): \"success\" or \"error\".\n            - papers (List[dict]): On success, a list of paper metadata objects, each with:\n                - title (str)\n                - authors (List[str])\n                - year (Optional[int])\n                - venue (Optional[str])  # Journal or conference (best-effort)\n                - url (Optional[str])\n                - abstract (Optional[str])  # Snippet / short description\n            - error_message (str, optional): Present if status == \"error\".\n    \"\"\"\n    if not SERPAPI_API_KEY:\n        return {\n            \"status\": \"error\",\n            \"error_message\": \"SERPAPI_API_KEY environment variable is not set.\",\n            \"papers\": [],\n        }\n\n    try:\n        response = requests.get(\n            \"https://serpapi.com/search.json\",\n            params={\n                \"engine\": \"google_scholar\",\n                \"q\": query,\n                \"num\": max_results,\n                \"api_key\": SERPAPI_API_KEY,\n            },\n            timeout=10,\n        )\n        response.raise_for_status()\n        data = response.json()\n\n        raw_results: List[Dict] = data.get(\"organic_results\", [])\n\n        papers: List[Dict] = []\n        for item in raw_results[:max_results]:\n            pub_info: Dict = item.get(\"publication_info\", {}) or {}\n\n            # Authors as simple list of names\n            authors_raw = pub_info.get(\"authors\", []) or []\n            authors: List[str] = []\n            for a in authors_raw:\n                name = a.get(\"name\")\n                if name:\n                    authors.append(name)\n\n            # Year as int if possible\n            year: Optional[int] = None\n            year_raw = pub_info.get(\"year\")\n            \n            if isinstance(year_raw, int):\n                year = year_raw\n            elif isinstance(year_raw, str):\n                # try direct parse first\n                if year_raw.isdigit():\n                    year = int(year_raw)\n                else:\n                    # extract first 4-digit year\n                    m = re.search(r\"\\b(19|20)\\d{2}\\b\", year_raw)\n                    if m:\n                        year = int(m.group(0))\n            \n            # if still None, try to parse from summary\n            if year is None:\n                summary = pub_info.get(\"summary\") or \"\"\n                m = re.search(r\"\\b(19|20)\\d{2}\\b\", summary)\n                if m:\n                    year = int(m.group(0))\n\n            # Venue: best-effort from summary\n            venue: Optional[str] = pub_info.get(\"summary\")\n\n            # Citations (if available)\n            inline_links = item.get(\"inline_links\", {}) or {}\n            cited_by = inline_links.get(\"cited_by\", {}) or {}\n            citations_raw = (\n                cited_by.get(\"cited_by_count\")\n                or cited_by.get(\"total\")\n                or cited_by.get(\"value\")      # just in case other schema variants\n            )\n\n            citations: Optional[int] = None\n            if isinstance(citations_raw, (int, float)):\n                citations = int(citations_raw)\n            elif isinstance(citations_raw, str):\n                # keep only digits\n                digits = re.sub(r\"[^\\d]\", \"\", citations_raw)\n                if digits:\n                    citations = int(digits)\n\n            papers.append(\n                {\n                    \"title\": item.get(\"title\"),\n                    \"authors\": authors,\n                    \"year\": year,\n                    \"venue\": venue,\n                    \"url\": item.get(\"link\"),\n                    \"abstract\": item.get(\"snippet\"),\n                    \"citations\": citations,\n                }\n            )\n\n        return {\n            \"status\": \"success\",\n            \"papers\": papers,\n        }\n\n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"error_message\": f\"Failed to search scholar backend: {e}\",\n            \"papers\": [],\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:09.036655Z","iopub.execute_input":"2025-11-29T21:01:09.037762Z","iopub.status.idle":"2025-11-29T21:01:09.054167Z","shell.execute_reply.started":"2025-11-29T21:01:09.037717Z","shell.execute_reply":"2025-11-29T21:01:09.052813Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# SearchAgent\n\nSEARCH_AGENT_INSTRUCTION = \"\"\"\nYou are a specialized research search agent.\n\nYour job:\n- Given research keywords, topics, or a question, use the `google_scholar_search` tool\n  to retrieve academic papers that are relevant to the query.\n- Never invent or fabricate papers, authors, venues, DOIs, URLs, years, or citation counts.\n  You must only use information returned by the `google_scholar_search` tool.\n- Focus on finding recent, high-quality, and thematically relevant works.\n\nHow to behave:\n- For every user query, you MUST call the `google_scholar_search` tool at least once.\n- Do NOT summarize, rewrite, or reformat the tool results in your own words.\n- Do NOT attempt to manually construct JSON or BibTeX.\n- Another agent in the system will handle ranking, formatting, and BibTeX generation.\n\nOutput:\n- The system will read the `google_scholar_search` tool response directly (as structured data).\n- Your own final message is not used downstream, so keep it minimal (or empty) and NEVER add\n  extra invented metadata.\n\"\"\"\n\n\nsearch_agent = Agent(\n    name=\"google_scholar_search_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Agent that takes research keywords or topics and finds relevant \"\n        \"academic papers using the SerpAPI Google Scholar API.\"\n    ),\n    instruction=SEARCH_AGENT_INSTRUCTION,\n    tools=[google_scholar_search],\n)\n\n\nprint(\"âœ… Search Agent defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:14.651696Z","iopub.execute_input":"2025-11-29T21:01:14.652008Z","iopub.status.idle":"2025-11-29T21:01:14.660141Z","shell.execute_reply.started":"2025-11-29T21:01:14.651983Z","shell.execute_reply":"2025-11-29T21:01:14.658976Z"}},"outputs":[{"name":"stdout","text":"âœ… Search Agent defined.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#PaperSelectionAgent ()\n\ndef extract_json_from_text(text: str):\n    \"\"\"\n    Best-effort extraction of a single JSON object from a model response.\n    Handles optional ```json fences and surrounding text.\n    \"\"\"\n    text = text.strip()\n\n    # Strip markdown fences\n    if text.startswith(\"```\"):\n        lines = text.splitlines()\n        # drop first line (``` or ```json)\n        lines = lines[1:]\n        # drop last line if it is ```-like\n        if lines and lines[-1].strip().startswith(\"```\"):\n            lines = lines[:-1]\n        text = \"\\n\".join(lines).strip()\n\n    # Take substring from first '{' to last '}'\n    start = text.find(\"{\")\n    end = text.rfind(\"}\")\n    if start == -1 or end == -1 or end <= start:\n        raise ValueError(\"No JSON object found in text.\")\n\n    json_str = text[start : end + 1]\n    import json\n    return json.loads(json_str)\n\ndef build_selection_prompt(original_query: str, papers: list, user_pref: str) -> str:\n    return f\"\"\"\nYou are given:\n- User query: {original_query!r}\n- User ranking preference: {user_pref!r}\n  (one of: \"similarity\", \"recency\", \"citations\")\n\nHere is the list of papers in JSON format:\n\n{json.dumps(papers, ensure_ascii=False, indent=2)}\n\nRank these papers according to the user ranking preference, following your instructions.\nRemember: do NOT drop any papers, only reorder them.\n\nReturn ONLY a JSON object with keys:\n- \"criterion\": string (how you interpreted the ranking criterion)\n- \"papers_ranked\": list of paper objects with the same fields as the input plus:\n    - \"rank\": integer (1 is top)\n    - optional \"score\": number between 0 and 1\n\"\"\"\n\n\npaper_selection_description = (\n    \"Agent that ranks a list of academic papers according to user-defined criteria \"\n    \"(similarity to query, recency, or citation count). It never discards papers, \"\n    \"only reorders them.\"\n)\nPAPER_SELECTION_INSTRUCTION = \"\"\"\nYou are a paper-ranking agent.\n\nYou will receive:\n- the original user query (research topic or question)\n- a list of paper objects in JSON format\n- a ranking preference from the user\n\nEach paper has at least:\n- title: string\n- authors: list of strings\n- year: integer or null\n- venue: string or null\n- url: string or null\n- abstract: string or null\n- citations: integer or null\n\nYour task:\n1. DO NOT remove any papers. Keep all of them.\n2. Sort the papers according to the user preference:\n\n   - If the user prefers \"similarity\" or \"relevance\":\n       Rank papers by how semantically relevant they are to the original query.\n       Use title and abstract to judge relevance.\n   - If the user prefers \"recency\" or \"newer\":\n       Rank newer papers first (higher year first). If year is missing, put them last.\n   - If the user prefers \"citations\" or \"highly cited\":\n       Rank papers with higher `citations` first. If citations is null, treat it as 0.\n\n3. For each paper, you may optionally provide:\n   - rank: integer (1 is best)\n   - score: a relevance or sorting score between 0 and 1 (optional)\n\nOutput format:\nReturn ONLY a JSON object with this structure (no extra text):\n\n{\n  \"criterion\": \"<the interpreted ranking criterion>\",\n  \"papers_ranked\": [\n    {\n      \"title\": \"...\",\n      \"authors\": [\"...\", \"...\"],\n      \"year\": 2024,\n      \"venue\": \"...\",\n      \"url\": \"...\",\n      \"abstract\": \"...\",\n      \"citations\": 123,\n      \"rank\": 1,\n      \"score\": 0.95\n    }\n  ]\n}\n\"\"\"\n\npaper_selection_agent = Agent(\n    name=\"paper_selection_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash\",\n        retry_options=retry_config,\n    ),\n    description=paper_selection_description,\n    instruction=PAPER_SELECTION_INSTRUCTION,\n    tools=[],  # no external tools needed, just reasoning\n)\n\nprint(\"âœ… Paper Selection Agent defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:20.288268Z","iopub.execute_input":"2025-11-29T21:01:20.289501Z","iopub.status.idle":"2025-11-29T21:01:20.301209Z","shell.execute_reply.started":"2025-11-29T21:01:20.289454Z","shell.execute_reply":"2025-11-29T21:01:20.300268Z"}},"outputs":[{"name":"stdout","text":"âœ… Paper Selection Agent defined.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# BibtexBuilderAgent\n\ndef build_bibtex_entry(\n    title: str,\n    authors: List[str],\n    year: Optional[int] = None,\n    venue: Optional[str] = None,\n    url: Optional[str] = None,\n    entry_type: str = \"article\",\n    key_prefix: str = \"\",\n) -> str:\n    \"\"\"\n    Build a BibTeX entry from paper metadata.\n\n    Args:\n        title: Paper title.\n        authors: List of author names as strings.\n        year: Publication year (optional).\n        venue: Journal or conference name (optional).\n        url: URL to the paper (optional).\n        entry_type: BibTeX entry type, e.g. \"article\", \"inproceedings\".\n        key_prefix: Optional prefix for the citation key.\n\n    Returns:\n        A single BibTeX entry as a string.\n    \"\"\"\n\n    title = (title or \"\").strip()\n    authors_list = authors or []\n    venue = (venue or \"\").strip()\n    url = (url or \"\").strip()\n\n    # BibTeX key, e.g. Hadaeghi2025 or NSL_Hadaeghi2025\n    first_author = authors_list[0] if authors_list else \"anon\"\n    first_author_token = re.sub(r\"[^A-Za-z0-9]\", \"\", first_author.split()[-1]) or \"anon\"\n    year_token = str(year) if year is not None else \"\"\n    key_base = f\"{first_author_token}{year_token}\"\n    if key_prefix:\n        safe_prefix = re.sub(r\"[^A-Za-z0-9]\", \"\", key_prefix)\n        key = f\"{safe_prefix}_{key_base}\"\n    else:\n        key = key_base\n\n    authors_bib = \" and \".join(authors_list)\n\n    entry_lines = [\n        f\"@{entry_type}{{{key},\",\n        f\"  title = {{{title}}},\",\n        f\"  author = {{{authors_bib}}},\",\n    ]\n    if venue:\n        entry_lines.append(f\"  journal = {{{venue}}},\")\n    if year is not None:\n        entry_lines.append(f\"  year = {{{year}}},\")\n    if url:\n        entry_lines.append(f\"  url = {{{url}}},\")\n    entry_lines.append(\"}\")\n\n    return \"\\n\".join(entry_lines) + \"\\n\"\n\n\nBIBTEX_FORMATTER_INSTRUCTION = \"\"\"\nYou are a BibTeX formatting agent.\n\nInput:\n- A list of paper metadata dictionaries (already ranked).\n- A user-specified style string, e.g. \"default\", \"ieee\", \"nature\", \"apa-like\",\n  or custom journal-specific instructions (such as \"use abbreviated journal names\").\n\nEach paper dict has:\n- title: string\n- authors: list of strings\n- year: integer or null\n- venue: string or null\n- url: string or null\n- citations: integer or null (not needed for BibTeX)\n\nYour job:\n- For each paper, call the `build_bibtex_entry` tool with the following parameters:\n    - title (string)\n    - authors (list of strings)\n    - year (integer or null)\n    - venue (string or null)\n    - url (string or null)\n    - entry_type (string, e.g. \"article\")\n    - key_prefix (string, may be provided in the user instructions)\n- Do NOT invent DOIs, volume, issue, or page numbers that are not provided.\n- You MAY adapt fields to follow the requested style, for example:\n  - choose entry_type (\"article\", \"inproceedings\") based on venue text,\n  - adjust venue string (e.g., abbreviate) if the style explicitly asks,\n  - include or omit the url field depending on style.\n- However, you MUST keep all information factually consistent with the provided metadata.\n  No hallucinated data.\n\nOutput:\n- Return ONLY the concatenation of all BibTeX entries, separated by one blank line.\n- Do NOT wrap the output in markdown fences (no ```).\n- Do NOT add any explanation or commentary.\n\"\"\"\n\nbibtex_formatter_agent = Agent(\n    name=\"bibtex_formatter_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash\",\n        retry_options=retry_config,\n    ),\n    description=(\n        \"Agent that converts structured paper metadata into harmonized BibTeX entries, \"\n        \"respecting user-defined citation styles.\"\n    ),\n    instruction=BIBTEX_FORMATTER_INSTRUCTION,\n    tools=[build_bibtex_entry],\n)\n\nprint(\"âœ…  Bibtex Builder Agent defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:29.206156Z","iopub.execute_input":"2025-11-29T21:01:29.206655Z","iopub.status.idle":"2025-11-29T21:01:29.219324Z","shell.execute_reply.started":"2025-11-29T21:01:29.206621Z","shell.execute_reply":"2025-11-29T21:01:29.218070Z"}},"outputs":[{"name":"stdout","text":"âœ…  Bibtex Builder Agent defined.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Runners for three agents\n\nasync def run_search_with_tool_output(runner: InMemoryRunner, query: str, max_results: int) -> dict:\n    \"\"\"\n    Run search_agent and return the google_scholar_search tool response as a Python dict:\n    {\n      \"status\": \"success\" | \"error\",\n      \"papers\": [ ... ]\n    }\n    \"\"\"\n    session = await runner.session_service.create_session(\n        app_name=runner.app_name,\n        user_id=\"demo_user\",\n    )\n\n    user_msg = types.Content(\n        role=\"user\",\n        parts=[types.Part(text=query)]\n    )\n\n    tool_response = None\n\n    async for event in runner.run_async(\n        user_id=\"demo_user\",\n        session_id=session.id,\n        new_message=user_msg,\n    ):\n        if event.content and event.content.parts:\n            for part in event.content.parts:\n                fr = getattr(part, \"function_response\", None)\n                if fr and fr.name == \"google_scholar_search\":\n                    tool_response = fr.response\n\n    if tool_response is None:\n        raise RuntimeError(\"google_scholar_search tool did not return a response.\")\n\n    return tool_response\n\n\nasync def run_paper_selection(\n    runner: InMemoryRunner,\n    original_query: str,\n    papers: list,\n    user_pref: str,\n) -> str:\n    \"\"\"\n    Call paper_selection_agent and return its final text output (JSON string).\n    \"\"\"\n    session = await runner.session_service.create_session(\n        app_name=runner.app_name,\n        user_id=\"demo_user\",\n    )\n\n    prompt = build_selection_prompt(original_query, papers, user_pref)\n\n    user_msg = types.Content(\n        role=\"user\",\n        parts=[types.Part(text=prompt)]\n    )\n\n    final_text = \"\"\n\n    async for event in runner.run_async(\n        user_id=\"demo_user\",\n        session_id=session.id,\n        new_message=user_msg,\n    ):\n        if event.is_final_response() and event.content and event.content.parts:\n            final_text = \"\".join(\n                part.text or \"\" for part in event.content.parts\n                if getattr(part, \"text\", None)\n            )\n\n    return final_text\n\nasync def run_bibtex_formatter(\n    runner: InMemoryRunner,\n    papers_ranked: list,\n    style: str,\n    key_prefix: str = \"\",\n) -> str:\n    session = await runner.session_service.create_session(\n        app_name=runner.app_name,\n        user_id=\"demo_user\",\n    )\n\n    prompt = f\"\"\"\nYou are given a list of ranked papers (JSON) and a style string.\n\nStyle: {style!r}\n\nPapers:\n\n{json.dumps(papers_ranked, ensure_ascii=False, indent=2)}\n\nUsing the instructions you have, call the `build_bibtex_entry` tool for each paper,\npassing title, authors, year, venue, url, entry_type and key_prefix={key_prefix!r}\nto the tool.\n\nReturn ONLY the concatenated BibTeX entries, separated by blank lines.\nDo NOT wrap the output in markdown fences and do NOT add any explanation.\n\"\"\"\n\n    from google.genai import types\n    user_msg = types.Content(\n        role=\"user\",\n        parts=[types.Part(text=prompt)]\n    )\n\n    final_text = \"\"\n    async for event in runner.run_async(\n        user_id=\"demo_user\",\n        session_id=session.id,\n        new_message=user_msg,\n    ):\n        if event.is_final_response() and event.content and event.content.parts:\n            final_text = \"\".join(\n                part.text or \"\" for part in event.content.parts\n                if getattr(part, \"text\", None)\n            )\n\n    return final_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:38.989839Z","iopub.execute_input":"2025-11-29T21:01:38.990487Z","iopub.status.idle":"2025-11-29T21:01:39.003365Z","shell.execute_reply.started":"2025-11-29T21:01:38.990456Z","shell.execute_reply":"2025-11-29T21:01:39.002217Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"async def run_full_pipeline(\n    search_runner: InMemoryRunner,\n    selection_runner: InMemoryRunner,\n    bibtex_runner: InMemoryRunner,\n    user_query: str,\n    max_results: int,\n    ranking_pref: str = \"similarity\",   # or \"recency\" or \"citations\"\n    style: str = \"default\",             # e.g. \"ieee\", \"nature\", journal-specific\n    output_path: str = \"results.bib\",\n):\n    # 1. Search\n    search_result = await run_search_with_tool_output(search_runner, user_query, max_results)\n    if search_result.get(\"status\") != \"success\":\n        raise RuntimeError(f\"Search failed: {search_result}\")\n\n    papers = search_result.get(\"papers\", [])\n    if not papers:\n        raise RuntimeError(\"No papers returned by search.\")\n\n    # 2. Rank\n    selection_raw = await run_paper_selection(\n        selection_runner,\n        original_query=user_query,\n        papers=papers,\n        user_pref=ranking_pref,\n    )\n    selection_data = extract_json_from_text(selection_raw)\n    papers_ranked = selection_data.get(\"papers_ranked\", [])\n    if not papers_ranked:\n        raise RuntimeError(\"PaperSelectionAgent did not return 'papers_ranked'.\")\n\n    # 3. Format BibTeX\n    bibtex_text = await run_bibtex_formatter(\n        bibtex_runner,\n        papers_ranked=papers_ranked,\n        style=style,\n        key_prefix=\"NSL\",   # example prefix for \"No Strong Loop\"\n    )\n\n    # 4. Save to .bib file\n    output_path = os.path.abspath(output_path)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(bibtex_text)\n\n    print(f\"âœ… BibTeX file saved to: {output_path}\")\n    return output_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:01:49.207824Z","iopub.execute_input":"2025-11-29T21:01:49.208136Z","iopub.status.idle":"2025-11-29T21:01:49.217079Z","shell.execute_reply.started":"2025-11-29T21:01:49.208113Z","shell.execute_reply":"2025-11-29T21:01:49.215779Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import logging\n\n# Put this once at startup, before you start calling the runner\nlogging.getLogger(\"google_genai.types\").setLevel(logging.ERROR)\n\nsearch_runner = InMemoryRunner(agent=search_agent)\nselection_runner = InMemoryRunner(agent=paper_selection_agent)\nbibtex_runner = InMemoryRunner(agent=bibtex_formatter_agent)\n\nuser_query = \"no strong loop hypothesis in brain networks\"\n\n# In a notebook / async context:\noutput_file = await run_full_pipeline(\n    search_runner=search_runner,\n    selection_runner=selection_runner,\n    bibtex_runner=bibtex_runner,\n    user_query=user_query,\n    max_results=20,\n    ranking_pref=\"similarity\",   # or \"similarity\", \"recency\", \"citations\"\n    style=\"ieee, abbreviated journal names\",\n    output_path=\"no_strong_loop.bib\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:09:53.840325Z","iopub.execute_input":"2025-11-29T21:09:53.840691Z","iopub.status.idle":"2025-11-29T21:11:05.671846Z","shell.execute_reply.started":"2025-11-29T21:09:53.840664Z","shell.execute_reply":"2025-11-29T21:11:05.670697Z"}},"outputs":[{"name":"stdout","text":"âœ… BibTeX file saved to: /kaggle/working/no_strong_loop.bib\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Load the saved file to control output\nfile_path = \"/kaggle/working/no_strong_loop.bib\"\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    lines = f.readlines()\n\nprint(f\"ðŸ“„ Loaded: {file_path}\")\nprint(\"----------------------------------------\")\n\nfor i, line in enumerate(lines, start=1):\n    print(f\"{i:3d} | {line.rstrip()}\")\n\nprint(\"----------------------------------------\")\nprint(f\"Total lines: {len(lines)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T21:12:12.560221Z","iopub.execute_input":"2025-11-29T21:12:12.560603Z","iopub.status.idle":"2025-11-29T21:12:12.570076Z","shell.execute_reply.started":"2025-11-29T21:12:12.560576Z","shell.execute_reply":"2025-11-29T21:12:12.568559Z"}},"outputs":[{"name":"stdout","text":"ðŸ“„ Loaded: /kaggle/working/no_strong_loop.bib\n----------------------------------------\n  1 | @article{NSL_Hadaeghi2025,\n  2 |   title = {A computational perspective on the no-strong-loops principle in brain networks},\n  3 |   author = {F Hadaeghi and K Fakhar and M Khajehnejad and CC Hilgetag},\n  4 |   journal = {bioRxiv},\n  5 |   year = {2025},\n  6 |   url = {https://www.biorxiv.org/content/10.1101/2025.09.24.678310.abstract},\n  7 | }\n  8 | \n  9 | @article{NSL_Sokolov2018,\n 10 |   title = {Structural and effective brain connectivity underlying biological motion detection},\n 11 |   author = {AA Sokolov and P Zeidman and M Erb and P Ryvlin},\n 12 |   journal = {Proc. Natl. Acad. Sci. U. S. A.},\n 13 |   year = {2018},\n 14 |   url = {https://www.pnas.org/doi/abs/10.1073/pnas.1812859115},\n 15 | }\n 16 | \n 17 | @article{NSL_Papo2014,\n 18 |   title = {Functional brain networks: great expectations, hard times and the big leap forward},\n 19 |   author = {D Papo and M Zanin and JA Pineda-Pardo},\n 20 |   journal = {Phil. Trans. R. Soc. B},\n 21 |   year = {2014},\n 22 |   url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2013.0525},\n 23 | }\n 24 | \n 25 | @article{NSL_Dirkx2016,\n 26 |   title = {The cerebral network of Parkinson's tremor: an effective connectivity fMRI study},\n 27 |   author = {MF Dirkx and H den Ouden and E Aarts and M Timmer},\n 28 |   journal = {J. Neurosci.},\n 29 |   year = {2016},\\n  url = {https://www.jneurosci.org/content/36/19/5362.short},\n 30 | }\n 31 | \n 32 | @article{NSL_Garrido2007,\n 33 |   title = {Evoked brain responses are generated by feedback loops},\n 34 |   author = {MI Garrido and JM Kilner and SJ Kiebel and KJ Friston},\n 35 |   journal = {Proc. Natl. Acad. Sci. U. S. A.},\n 36 |   year = {2007},\n 37 |   url = {https://www.pnas.org/doi/abs/10.1073/pnas.0706274105},\n 38 | }\n 39 | \n 40 | @article{NSL_Sporns2018,\n 41 |   title = {Graph theory methods: applications in brain networks},\n 42 |   author = {O Sporns},\n 43 |   journal = {Dialogues Clin. Neurosci.},\n 44 |   year = {2018},\n 45 |   url = {https://www.tandfonline.com/doi/abs/10.31887/DCNS.2018.20.2/osporns},\n 46 | }\n 47 | \n 48 | @article{NSL_Weiller2025,\n 49 |   title = {Hubs and interaction: The brain's meta-loop},\n 50 |   author = {C Weiller and M Reisert and P Levan and J Hosp},\n 51 |   journal = {Cereb. Cortex},\n 52 |   year = {2025},\n 53 |   url = {https://academic.oup.com/cercor/article-abstract/35/3/bhaf035/8074199},\n 54 | }\n 55 | \n 56 | @article{NSL_Papagno2017,\n 57 |   title = {Mapping the brain network of the phonological loop},\n 58 |   author = {C Papagno and A Comi and M Riva and A Bizzi},\n 59 |   journal = {Hum. Brain Mapp.},\n 60 |   year = {2017},\n 61 |   url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23569},\n 62 | }\n 63 | \n 64 | @article{NSL_Nishida2017,\n 65 |   title = {Brain network dynamics in the human articulatory loop},\n 66 |   author = {M Nishida and A Korzeniewska and NE Crone and G Toyoda},\n 67 |   journal = {Clin. Neurophysiol.},\n 68 |   year = {2017},\n 69 |   url = {https://www.sciencedirect.com/science/article/pii/S1388245717301852},\n 70 | }\n 71 | \n 72 | @techreport{NSL_Caswell2016,\n 73 |   title = {Loopy neural nets: Imitating feedback loops in the human brain},\n 74 |   author = {I Caswell and C Shen and L Wang},\n 75 |   journal = {Tech. Rep.},\n 76 |   year = {2016},\n 77 |   url = {https://lisa-1010.github.io/cs231n_project/loopy_cnns_paper.pdf},\n 78 | }\n 79 | \n 80 | @article{NSL_Tang2018,\n 81 |   title = {Colloquium: Control of dynamics in brain networks},\n 82 |   author = {E Tang and DS Bassett},\n 83 |   journal = {Rev. Mod. Phys.},\n 84 |   year = {2018},\n 85 |   url = {https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.90.031003},\n 86 | }\n 87 | \n 88 | @article{NSL_Bassett2017,\n 89 |   title = {Small-world brain networks revisited},\n 90 |   author = {DS Bassett and ET Bullmore},\n 91 |   journal = {Neuroscientist},\n 92 |   year = {2017},\n 93 |   url = {https://journals.sagepub.com/doi/abs/10.1177/1073858416667720},\n 94 | }\n 95 | \n 96 | @article{NSL_Zalesky2012,\n 97 |   title = {Connectivity differences in brain networks},\n 98 |   author = {A Zalesky and L Cocchi and A Fornito and MM Murray},\n 99 |   journal = {Neuroimage},\n100 |   year = {2012},\n101 |   url = {https://www.sciencedirect.com/science/article/pii/S1053811912000857},\n102 | }\n103 | \n104 | @article{NSL_Lynn2019,\n105 |   title = {The physics of brain network structure, function and control},\n106 |   author = {CW Lynn and DS Bassett},\n107 |   journal = {Nat. Rev. Phys.},\n108 |   year = {2019},\n109 |   url = {https://www.nature.com/articles/s42254-019-0040-8},\n110 | }\n111 | \n112 | @article{NSL_Bassett2006,\n113 |   title = {Small-world brain networks},\n114 |   author = {DS Bassett and ED Bullmore},\n115 |   journal = {Neuroscientist},\n116 |   year = {2006},\n117 |   url = {https://journals.sagepub.com/doi/abs/10.1177/1073858406293182},\n118 | }\n119 | \n120 | @article{NSL_Papo2014,\n121 |   title = {Complex network theory and the brain},\n122 |   author = {D Papo and JM BuldÃº and S Boccaletti},\n123 |   journal = {Phil. Trans. R. Soc. B},\n124 |   year = {2014},\n125 |   url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2013.0520},\n126 | }\n127 | \n128 | @article{NSL_Stam2007,\n129 |   title = {Graph theoretical analysis of complex networks in the brain},\n130 |   author = {CJ Stam and JC Reijneveld},\n131 |   journal = {Nonlin. Biomed. Phys.},\n132 |   year = {2007},\n133 |   url = {https://link.springer.com/article/10.1186/1753-4631-1-3},\n134 | }\n135 | \n136 | @article{NSL_Chialvo2004,\n137 |   title = {Critical brain networks},\n138 |   author = {DR Chialvo},\n139 |   journal = {Phys. A},\n140 |   year = {2004},\n141 |   url = {https://www.sciencedirect.com/science/article/pii/S0378437104005734},\n142 | }\n143 | \n144 | @article{NSL_Park2013,\n145 |   title = {Structural and functional brain networks: from connections to cognition},\n146 |   author = {HJ Park and K Friston},\n147 |   journal = {Science},\n148 |   year = {2013},\n149 |   url = {https://www.science.org/doi/abs/10.1126/science.1238411},\n150 | }\n151 | \n152 | @article{NSL_Rubinov2010,\n153 |   title = {Complex network measures of brain connectivity: uses and interpretations},\n154 |   author = {M Rubinov and O Sporns},\n155 |   journal = {Neuroimage},\n156 |   year = {2010},\n157 |   url = {https://www.sciencedirect.com/science/article/pii/S105381190901074X},\n158 | }\n----------------------------------------\nTotal lines: 158\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}